F. Operations
------------

F.Callable (*args, **kwargs)

F.List (*args, **kwargs)

F.Optional (*args, **kwds)

F.Tuple (*args, **kwargs)

F.Union (*args, **kwds)

F.adaptive_avg_pool1d
  Built-in function

F.adaptive_avg_pool2d (input: torch.Tensor, output_size: None) -> torch.Tensor

F.adaptive_avg_pool3d (input: torch.Tensor, output_size: None) -> torch.Tensor

F.adaptive_max_pool1d (*args, **kwargs)

F.adaptive_max_pool1d_with_indices (input: torch.Tensor, output_size: None, return_indices: bool = False) -> Tuple[torch.Tensor, torch.Tensor]

F.adaptive_max_pool2d (*args, **kwargs)

F.adaptive_max_pool2d_with_indices (input: torch.Tensor, output_size: None, return_indices: bool = False) -> Tuple[torch.Tensor, torch.Tensor]

F.adaptive_max_pool3d (*args, **kwargs)

F.adaptive_max_pool3d_with_indices (input: torch.Tensor, output_size: None, return_indices: bool = False) -> Tuple[torch.Tensor, torch.Tensor]

F.affine_grid (theta: torch.Tensor, size: List[int], align_corners: Optional[bool] = None) -> torch.Tensor

F.alpha_dropout (input: torch.Tensor, p: float = 0.5, training: bool = False, inplace: bool = False) -> torch.Tensor

F.assert_int_or_pair (arg: List[int], arg_name: str, message: str) -> None

F.avg_pool1d
  Built-in function

F.avg_pool2d
  Built-in function

F.avg_pool3d
  Built-in function

F.batch_norm (input: torch.Tensor, running_mean: Optional[torch.Tensor], running_var: Optional[torch.Tensor], weight: Optional[torch.Tensor] = None, bias: Optional[torch.Tensor] = None, training: bool = False, momentum: float = 0.1, eps: float = 1e-05) -> torch.Tensor

F.bilinear
  Built-in function

F.binary_cross_entropy (input: torch.Tensor, target: torch.Tensor, weight: Optional[torch.Tensor] = None, size_average: Optional[bool] = None, reduce: Optional[bool] = None, reduction: str = 'mean') -> torch.Tensor

F.binary_cross_entropy_with_logits (input: torch.Tensor, target: torch.Tensor, weight: Optional[torch.Tensor] = None, size_average: Optional[bool] = None, reduce: Optional[bool] = None, reduction: str = 'mean', pos_weight: Optional[torch.Tensor] = None) -> torch.Tensor

F.boolean_dispatch (arg_name, arg_index, default, if_true, if_false, module_name, func_name)

F.celu (input: torch.Tensor, alpha: float = 1.0, inplace: bool = False) -> torch.Tensor

F.celu_
  In-place operation
  Built-in function

F.channel_shuffle
  Built-in function

F.conv1d
  Built-in function

F.conv2d
  Built-in function

F.conv3d
  Built-in function

F.conv_tbc
  Built-in function

F.conv_transpose1d
  Built-in function

F.conv_transpose2d
  Built-in function

F.conv_transpose3d
  Built-in function

F.cosine_embedding_loss (input1: torch.Tensor, input2: torch.Tensor, target: torch.Tensor, margin: float = 0, size_average: Optional[bool] = None, reduce: Optional[bool] = None, reduction: str = 'mean') -> torch.Tensor

F.cosine_similarity
  Built-in function

F.cross_entropy (input: torch.Tensor, target: torch.Tensor, weight: Optional[torch.Tensor] = None, size_average: Optional[bool] = None, ignore_index: int = -100, reduce: Optional[bool] = None, reduction: str = 'mean', label_smoothing: float = 0.0) -> torch.Tensor

F.ctc_loss (log_probs: torch.Tensor, targets: torch.Tensor, input_lengths: torch.Tensor, target_lengths: torch.Tensor, blank: int = 0, reduction: str = 'mean', zero_infinity: bool = False) -> torch.Tensor

F.dropout (input: torch.Tensor, p: float = 0.5, training: bool = True, inplace: bool = False) -> torch.Tensor

F.dropout1d (input: torch.Tensor, p: float = 0.5, training: bool = True, inplace: bool = False) -> torch.Tensor

F.dropout2d (input: torch.Tensor, p: float = 0.5, training: bool = True, inplace: bool = False) -> torch.Tensor

F.dropout3d (input: torch.Tensor, p: float = 0.5, training: bool = True, inplace: bool = False) -> torch.Tensor

F.elu (input: torch.Tensor, alpha: float = 1.0, inplace: bool = False) -> torch.Tensor

F.elu_
  In-place operation
  Built-in function

F.embedding (input: torch.Tensor, weight: torch.Tensor, padding_idx: Optional[int] = None, max_norm: Optional[float] = None, norm_type: float = 2.0, scale_grad_by_freq: bool = False, sparse: bool = False) -> torch.Tensor

F.embedding_bag (input: torch.Tensor, weight: torch.Tensor, offsets: Optional[torch.Tensor] = None, max_norm: Optional[float] = None, norm_type: float = 2, scale_grad_by_freq: bool = False, mode: str = 'mean', sparse: bool = False, per_sample_weights: Optional[torch.Tensor] = None, include_last_offset: bool = False, padding_idx: Optional[int] = None) -> torch.Tensor

F.feature_alpha_dropout (input: torch.Tensor, p: float = 0.5, training: bool = False, inplace: bool = False) -> torch.Tensor

F.fold (input: torch.Tensor, output_size: None, kernel_size: None, dilation: None = 1, padding: None = 0, stride: None = 1) -> torch.Tensor

F.fractional_max_pool2d (*args, **kwargs)

F.fractional_max_pool2d_with_indices (input: torch.Tensor, kernel_size: None, output_size: NoneType = None, output_ratio: NoneType = None, return_indices: bool = False, _random_samples: Optional[torch.Tensor] = None) -> Tuple[torch.Tensor, torch.Tensor]

F.fractional_max_pool3d (*args, **kwargs)

F.fractional_max_pool3d_with_indices (input: torch.Tensor, kernel_size: None, output_size: NoneType = None, output_ratio: NoneType = None, return_indices: bool = False, _random_samples: Optional[torch.Tensor] = None) -> Tuple[torch.Tensor, torch.Tensor]

F.gaussian_nll_loss (input: torch.Tensor, target: torch.Tensor, var: Union[torch.Tensor, float], full: bool = False, eps: float = 1e-06, reduction: str = 'mean') -> torch.Tensor

F.gelu
  Built-in function

F.glu (input: torch.Tensor, dim: int = -1) -> torch.Tensor

F.grid_sample (input: torch.Tensor, grid: torch.Tensor, mode: str = 'bilinear', padding_mode: str = 'zeros', align_corners: Optional[bool] = None) -> torch.Tensor

F.group_norm (input: torch.Tensor, num_groups: int, weight: Optional[torch.Tensor] = None, bias: Optional[torch.Tensor] = None, eps: float = 1e-05) -> torch.Tensor

F.gumbel_softmax (logits: torch.Tensor, tau: float = 1, hard: bool = False, eps: float = 1e-10, dim: int = -1) -> torch.Tensor

F.handle_torch_function (public_api: Callable, relevant_args: Iterable[Any], *args, **kwargs) -> Any

F.hardshrink
  Built-in function

F.hardsigmoid (input: torch.Tensor, inplace: bool = False) -> torch.Tensor

F.hardswish (input: torch.Tensor, inplace: bool = False) -> torch.Tensor

F.hardtanh (input: torch.Tensor, min_val: float = -1.0, max_val: float = 1.0, inplace: bool = False) -> torch.Tensor

F.hardtanh_
  In-place operation
  Built-in function

F.has_torch_function
  Built-in function

F.has_torch_function_unary
  Built-in function

F.has_torch_function_variadic
  Built-in function

F.hinge_embedding_loss (input: torch.Tensor, target: torch.Tensor, margin: float = 1.0, size_average: Optional[bool] = None, reduce: Optional[bool] = None, reduction: str = 'mean') -> torch.Tensor

F.huber_loss (input: torch.Tensor, target: torch.Tensor, reduction: str = 'mean', delta: float = 1.0, weight: Optional[torch.Tensor] = None) -> torch.Tensor

F.instance_norm (input: torch.Tensor, running_mean: Optional[torch.Tensor] = None, running_var: Optional[torch.Tensor] = None, weight: Optional[torch.Tensor] = None, bias: Optional[torch.Tensor] = None, use_input_stats: bool = True, momentum: float = 0.1, eps: float = 1e-05) -> torch.Tensor

F.interpolate (input: torch.Tensor, size: Optional[int] = None, scale_factor: Optional[List[float]] = None, mode: str = 'nearest', align_corners: Optional[bool] = None, recompute_scale_factor: Optional[bool] = None, antialias: bool = False) -> torch.Tensor

F.kl_div (input: torch.Tensor, target: torch.Tensor, size_average: Optional[bool] = None, reduce: Optional[bool] = None, reduction: str = 'mean', log_target: bool = False) -> torch.Tensor

F.l1_loss (input: torch.Tensor, target: torch.Tensor, size_average: Optional[bool] = None, reduce: Optional[bool] = None, reduction: str = 'mean', weight: Optional[torch.Tensor] = None) -> torch.Tensor

F.layer_norm (input: torch.Tensor, normalized_shape: List[int], weight: Optional[torch.Tensor] = None, bias: Optional[torch.Tensor] = None, eps: float = 1e-05) -> torch.Tensor

F.leaky_relu (input: torch.Tensor, negative_slope: float = 0.01, inplace: bool = False) -> torch.Tensor

F.leaky_relu_
  In-place operation
  Built-in function

F.linear
  Built-in function

F.local_response_norm (input: torch.Tensor, size: int, alpha: float = 0.0001, beta: float = 0.75, k: float = 1.0) -> torch.Tensor

F.log_softmax (input: torch.Tensor, dim: Optional[int] = None, _stacklevel: int = 3, dtype: Optional[int] = None) -> torch.Tensor

F.logsigmoid
  Built-in function

F.lp_pool1d (input: torch.Tensor, norm_type: Union[int, float], kernel_size: int, stride: NoneType = None, ceil_mode: bool = False) -> torch.Tensor

F.lp_pool2d (input: torch.Tensor, norm_type: Union[int, float], kernel_size: None, stride: NoneType = None, ceil_mode: bool = False) -> torch.Tensor

F.lp_pool3d (input: torch.Tensor, norm_type: Union[int, float], kernel_size: None, stride: NoneType = None, ceil_mode: bool = False) -> torch.Tensor

F.margin_ranking_loss (input1: torch.Tensor, input2: torch.Tensor, target: torch.Tensor, margin: float = 0, size_average: Optional[bool] = None, reduce: Optional[bool] = None, reduction: str = 'mean') -> torch.Tensor

F.max_pool1d (*args, **kwargs)

F.max_pool1d_with_indices (input: torch.Tensor, kernel_size: None, stride: NoneType = None, padding: None = 0, dilation: None = 1, ceil_mode: bool = False, return_indices: bool = False) -> Tuple[torch.Tensor, torch.Tensor]

F.max_pool2d (*args, **kwargs)

F.max_pool2d_with_indices (input: torch.Tensor, kernel_size: None, stride: NoneType = None, padding: None = 0, dilation: None = 1, ceil_mode: bool = False, return_indices: bool = False) -> Tuple[torch.Tensor, torch.Tensor]

F.max_pool3d (*args, **kwargs)

F.max_pool3d_with_indices (input: torch.Tensor, kernel_size: None, stride: NoneType = None, padding: None = 0, dilation: None = 1, ceil_mode: bool = False, return_indices: bool = False) -> Tuple[torch.Tensor, torch.Tensor]

F.max_unpool1d (input: torch.Tensor, indices: torch.Tensor, kernel_size: None, stride: NoneType = None, padding: None = 0, output_size: NoneType = None) -> torch.Tensor

F.max_unpool2d (input: torch.Tensor, indices: torch.Tensor, kernel_size: None, stride: NoneType = None, padding: None = 0, output_size: NoneType = None) -> torch.Tensor

F.max_unpool3d (input: torch.Tensor, indices: torch.Tensor, kernel_size: None, stride: NoneType = None, padding: None = 0, output_size: NoneType = None) -> torch.Tensor

F.mish (input: torch.Tensor, inplace: bool = False) -> torch.Tensor

F.mse_loss (input: torch.Tensor, target: torch.Tensor, size_average: Optional[bool] = None, reduce: Optional[bool] = None, reduction: str = 'mean', weight: Optional[torch.Tensor] = None) -> torch.Tensor

F.multi_head_attention_forward (query: torch.Tensor, key: torch.Tensor, value: torch.Tensor, embed_dim_to_check: int, num_heads: int, in_proj_weight: Optional[torch.Tensor], in_proj_bias: Optional[torch.Tensor], bias_k: Optional[torch.Tensor], bias_v: Optional[torch.Tensor], add_zero_attn: bool, dropout_p: float, out_proj_weight: torch.Tensor, out_proj_bias: Optional[torch.Tensor], training: bool = True, key_padding_mask: Optional[torch.Tensor] = None, need_weights: bool = True, attn_mask: Optional[torch.Tensor] = None, use_separate_proj_weight: bool = False, q_proj_weight: Optional[torch.Tensor] = None, k_proj_weight: Optional[torch.Tensor] = None, v_proj_weight: Optional[torch.Tensor] = None, static_k: Optional[torch.Tensor] = None, static_v: Optional[torch.Tensor] = None, average_attn_weights: bool = True, is_causal: bool = False) -> Tuple[torch.Tensor, Optional[torch.Tensor]]

F.multi_margin_loss (input: torch.Tensor, target: torch.Tensor, p: int = 1, margin: float = 1.0, weight: Optional[torch.Tensor] = None, size_average: Optional[bool] = None, reduce: Optional[bool] = None, reduction: str = 'mean') -> torch.Tensor

F.multilabel_margin_loss (input: torch.Tensor, target: torch.Tensor, size_average: Optional[bool] = None, reduce: Optional[bool] = None, reduction: str = 'mean') -> torch.Tensor

F.multilabel_soft_margin_loss (input: torch.Tensor, target: torch.Tensor, weight: Optional[torch.Tensor] = None, size_average: Optional[bool] = None, reduce: Optional[bool] = None, reduction: str = 'mean') -> torch.Tensor

F.native_channel_shuffle
  Built-in function

F.nll_loss (input: torch.Tensor, target: torch.Tensor, weight: Optional[torch.Tensor] = None, size_average: Optional[bool] = None, ignore_index: int = -100, reduce: Optional[bool] = None, reduction: str = 'mean') -> torch.Tensor

F.normalize (input: torch.Tensor, p: float = 2.0, dim: int = 1, eps: float = 1e-12, out: Optional[torch.Tensor] = None) -> torch.Tensor

F.one_hot
  Built-in function

F.pad (input: torch.Tensor, pad: List[int], mode: str = 'constant', value: Optional[float] = None) -> torch.Tensor

F.pairwise_distance
  Built-in function

F.pdist
  Built-in function

F.pixel_shuffle
  Built-in function

F.pixel_unshuffle
  Built-in function

F.poisson_nll_loss (input: torch.Tensor, target: torch.Tensor, log_input: bool = True, full: bool = False, size_average: Optional[bool] = None, eps: float = 1e-08, reduce: Optional[bool] = None, reduction: str = 'mean') -> torch.Tensor

F.prelu
  Built-in function

F.relu (input: torch.Tensor, inplace: bool = False) -> torch.Tensor

F.relu6 (input: torch.Tensor, inplace: bool = False) -> torch.Tensor

F.relu_
  In-place operation
  Built-in function

F.rms_norm (input: torch.Tensor, normalized_shape: List[int], weight: Optional[torch.Tensor] = None, eps: Optional[float] = None) -> torch.Tensor

F.rrelu (input: torch.Tensor, lower: float = 0.125, upper: float = 0.3333333333333333, training: bool = False, inplace: bool = False) -> torch.Tensor

F.rrelu_
  In-place operation
  Built-in function

F.scaled_dot_product_attention
  Built-in function

F.selu (input: torch.Tensor, inplace: bool = False) -> torch.Tensor

F.selu_
  In-place operation
  Built-in function

F.sigmoid (input)

F.silu (input: torch.Tensor, inplace: bool = False) -> torch.Tensor

F.smooth_l1_loss (input: torch.Tensor, target: torch.Tensor, size_average: Optional[bool] = None, reduce: Optional[bool] = None, reduction: str = 'mean', beta: float = 1.0) -> torch.Tensor

F.soft_margin_loss (input: torch.Tensor, target: torch.Tensor, size_average: Optional[bool] = None, reduce: Optional[bool] = None, reduction: str = 'mean') -> torch.Tensor

F.softmax (input: torch.Tensor, dim: Optional[int] = None, _stacklevel: int = 3, dtype: Optional[int] = None) -> torch.Tensor

F.softmin (input: torch.Tensor, dim: Optional[int] = None, _stacklevel: int = 3, dtype: Optional[int] = None) -> torch.Tensor

F.softplus
  Built-in function

F.softshrink
  Built-in function

F.softsign (input)

F.tanh (input)

F.tanhshrink (input)

F.threshold (input: torch.Tensor, threshold: float, value: float, inplace: bool = False) -> torch.Tensor

F.threshold_
  In-place operation
  Built-in function

F.triplet_margin_loss (anchor: torch.Tensor, positive: torch.Tensor, negative: torch.Tensor, margin: float = 1.0, p: float = 2, eps: float = 1e-06, swap: bool = False, size_average: Optional[bool] = None, reduce: Optional[bool] = None, reduction: str = 'mean') -> torch.Tensor

F.triplet_margin_with_distance_loss (anchor: torch.Tensor, positive: torch.Tensor, negative: torch.Tensor, *, distance_function: Optional[Callable[[torch.Tensor, torch.Tensor], torch.Tensor]] = None, margin: float = 1.0, swap: bool = False, reduction: str = 'mean') -> torch.Tensor

F.unfold (input: torch.Tensor, kernel_size: None, dilation: None = 1, padding: None = 0, stride: None = 1) -> torch.Tensor

F.upsample (input, size=None, scale_factor=None, mode='nearest', align_corners=None)

F.upsample_bilinear (input, size=None, scale_factor=None)

F.upsample_nearest (input, size=None, scale_factor=None)

