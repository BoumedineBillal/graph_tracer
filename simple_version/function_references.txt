
Torch functions:
AggregationType, AliasDb, AnyType, Argument, ArgumentSpec, AwaitType, BFloat16Storage, BFloat16Tensor, BenchmarkConfig, BenchmarkExecutionStats, Block, BoolStorage, BoolTensor, BoolType, BufferDict, ByteStorage, ByteTensor, CallStack, Capsule, CharStorage, CharTensor, ClassType, Code, CompilationUnit, CompleteArgumentSpec, ComplexDoubleStorage, ComplexFloatStorage, ComplexType, ConcreteModuleType, ConcreteModuleTypeBuilder, DeepCopyMemoTable, DeserializationStorageContext, DeviceObjType, DictType, DisableTorchFunction, DisableTorchFunctionSubclass, DispatchKey, DispatchKeySet, DoubleStorage, DoubleTensor, EnumType, ErrorReport, Event, ExcludeDispatchKeyGuard, ExecutionPlan, FatalError, FileCheck, FloatStorage, FloatTensor, FloatType, FunctionSchema, Future, FutureType, Generator, GradScaler, Gradient, Graph, GraphExecutorState, HalfStorage, HalfTensor, IODescriptor, InferredType, IntStorage, IntTensor, IntType, InterfaceType, JITException, ListType, LiteScriptModule, LockingLogger, LoggerBase, LongStorage, LongTensor, ModuleDict, Node, NoneType, NoopLogger, NumberType, OperatorInfo, OptionalType, OutOfMemoryError, ParameterDict, PyObjectType, PyTorchFileReader, PyTorchFileWriter, QInt32Storage, QInt8Storage, QUInt2x4Storage, QUInt4x2Storage, QUInt8Storage, RRefType, ScriptClass, ScriptClassFunction, ScriptDict, ScriptDictIterator, ScriptDictKeyIterator, ScriptFunction, ScriptList, ScriptListIterator, ScriptMethod, ScriptModule, ScriptModuleSerializer, ScriptObject, ScriptObjectProperty, SerializationStorageContext, ShortStorage, ShortTensor, Size, StaticModule, Storage, StorageBase, Stream, StreamObjType, StringType, SymBool, SymBoolType, SymFloat, SymInt, SymIntType, Tag, Tensor, TensorType, ThroughputBenchmark, TracingState, TupleType, Type, TypedStorage, UnionType, UntypedStorage, Use, Value, _Any, _Callable, _Dict, _InputT, _Optional, _ParamSpec, _Set, _TorchCompileInductorWrapper, _TorchCompileWrapper, _TritonLibrary, _Tuple, _Type, _TypeIs, _TypeVar, _Union, __all_and_float_types, __getattr__, _adaptive_avg_pool2d, _adaptive_avg_pool3d, _add_batch_dim, _add_relu, _add_relu_, _addmm_activation, _aminmax, _amp_foreach_non_finite_check_and_unscale_, _amp_update_scale_, _as_tensor_fullprec, _assert, _assert_async, _assert_scalar, _assert_tensor_metadata, _batch_norm_impl_index, _cast_Byte, _cast_Char, _cast_Double, _cast_Float, _cast_Half, _cast_Int, _cast_Long, _cast_Short, _check, _check_index, _check_is_size, _check_not_implemented, _check_tensor_all, _check_tensor_all_with, _check_type, _check_value, _check_with, _choose_qparams_per_tensor, _chunk_cat, _coalesce, _compute_linear_combination, _conj, _conj_copy, _conj_physical, _constrain_as_size, _convert_indices_from_coo_to_csr, _convert_indices_from_csr_to_coo, _convert_weight_to_int4pack, _convert_weight_to_int4pack_for_cpu, _convolution, _convolution_mode, _copy_from, _copy_from_and_resize, _cslt_compress, _cslt_sparse_mm, _cslt_sparse_mm_search, _ctc_loss, _cudnn_ctc_loss, _cudnn_init_dropout_state, _cudnn_rnn, _cudnn_rnn_flatten_weight, _cufft_clear_plan_cache, _cufft_get_plan_cache_max_size, _cufft_get_plan_cache_size, _cufft_set_plan_cache_max_size, _cummax_helper, _cummin_helper, _debug_has_internal_overlap, _dim_arange, _dirichlet_grad, _disable_dynamo, _disable_functionalization, _efficientzerotensor, _embedding_bag, _embedding_bag_forward_only, _empty_affine_quantized, _empty_per_channel_affine_quantized, _enable_functionalization, _euclidean_dist, _fake_quantize_learnable_per_channel_affine, _fake_quantize_learnable_per_tensor_affine, _fake_quantize_per_tensor_affine_cachemask_tensor_qparams, _fft_c2c, _fft_c2r, _fft_r2c, _fill_mem_eff_dropout_mask_, _foobar, _foreach_abs, _foreach_abs_, _foreach_acos, _foreach_acos_, _foreach_add, _foreach_add_, _foreach_addcdiv, _foreach_addcdiv_, _foreach_addcmul, _foreach_addcmul_, _foreach_asin, _foreach_asin_, _foreach_atan, _foreach_atan_, _foreach_ceil, _foreach_ceil_, _foreach_clamp_max, _foreach_clamp_max_, _foreach_clamp_min, _foreach_clamp_min_, _foreach_copy_, _foreach_cos, _foreach_cos_, _foreach_cosh, _foreach_cosh_, _foreach_div, _foreach_div_, _foreach_erf, _foreach_erf_, _foreach_erfc, _foreach_erfc_, _foreach_exp, _foreach_exp_, _foreach_expm1, _foreach_expm1_, _foreach_floor, _foreach_floor_, _foreach_frac, _foreach_frac_, _foreach_lerp, _foreach_lerp_, _foreach_lgamma, _foreach_lgamma_, _foreach_log, _foreach_log10, _foreach_log10_, _foreach_log1p, _foreach_log1p_, _foreach_log2, _foreach_log2_, _foreach_log_, _foreach_max, _foreach_maximum, _foreach_maximum_, _foreach_minimum, _foreach_minimum_, _foreach_mul, _foreach_mul_, _foreach_neg, _foreach_neg_, _foreach_norm, _foreach_pow, _foreach_pow_, _foreach_reciprocal, _foreach_reciprocal_, _foreach_round, _foreach_round_, _foreach_rsqrt, _foreach_rsqrt_, _foreach_sigmoid, _foreach_sigmoid_, _foreach_sign, _foreach_sign_, _foreach_sin, _foreach_sin_, _foreach_sinh, _foreach_sinh_, _foreach_sqrt, _foreach_sqrt_, _foreach_sub, _foreach_sub_, _foreach_tan, _foreach_tan_, _foreach_tanh, _foreach_tanh_, _foreach_trunc, _foreach_trunc_, _foreach_zero_, _freeze_functional_tensor, _from_functional_tensor, _functional_assert_async, _functional_assert_scalar, _functional_sym_constrain_range, _functional_sym_constrain_range_for_size, _functionalize_apply_view_metas, _functionalize_are_all_mutations_hidden_from_autograd, _functionalize_are_all_mutations_under_no_grad_or_inference_mode, _functionalize_commit_update, _functionalize_enable_reapply_views, _functionalize_get_storage_size, _functionalize_has_data_mutation, _functionalize_has_metadata_mutation, _functionalize_is_multi_output_view, _functionalize_is_symbolic, _functionalize_mark_mutation_hidden_from_autograd, _functionalize_replace, _functionalize_set_storage_changed, _functionalize_sync, _functionalize_unsafe_set, _functionalize_was_inductor_storage_resized, _functionalize_was_storage_changed, _fused_adagrad_, _fused_adam_, _fused_adamw_, _fused_dropout, _fused_moving_avg_obs_fq_helper, _fused_sdp_choice, _fused_sgd_, _fw_primal_copy, _get_origin, _grid_sampler_2d_cpu_fallback, _has_compatible_shallow_copy_type, _histogramdd_bin_edges, _histogramdd_from_bin_cts, _histogramdd_from_bin_tensors, _import_device_backends, _import_dotted_name, _index_put_impl_, _indices_copy, _initExtension, _int_mm, _is_all_true, _is_any_true, _is_device_backend_autoload_enabled, _is_functional_tensor, _is_functional_tensor_base, _is_zerotensor, _lazy_clone, _linalg_check_errors, _linalg_det, _linalg_eigh, _linalg_slogdet, _linalg_solve_ex, _linalg_svd, _load_global_deps, _log_softmax, _log_softmax_backward_data, _logcumsumexp, _lstm_mps, _lu_with_info, _make_dep_token, _make_dual, _make_dual_copy, _make_per_channel_quantized_tensor, _make_per_tensor_quantized_tensor, _masked_scale, _masked_softmax, _mirror_autograd_meta_to, _mixed_dtypes_linear, _mkldnn_reshape, _mkldnn_transpose, _mkldnn_transpose_, _mps_convolution, _mps_convolution_transpose, _native_batch_norm_legit, _native_batch_norm_legit_no_training, _native_multi_head_attention, _neg_view, _neg_view_copy, _nested_compute_contiguous_strides_offsets, _nested_from_padded, _nested_from_padded_and_nested_example, _nested_from_padded_tensor, _nested_get_jagged_dummy, _nested_get_lengths, _nested_get_max_seqlen, _nested_get_min_seqlen, _nested_get_offsets, _nested_get_ragged_idx, _nested_get_values, _nested_get_values_copy, _nested_tensor_from_mask, _nested_tensor_from_mask_left_aligned, _nested_tensor_from_tensor_list, _nested_tensor_softmax_with_shape, _nested_view_from_buffer, _nested_view_from_buffer_copy, _nested_view_from_jagged, _nested_view_from_jagged_copy, _nnpack_available, _nnpack_spatial_convolution, _overload, _pack_padded_sequence, _pad_packed_sequence, _pin_memory, _preload_cuda_deps, _prelu_kernel, _print, _propagate_xla_data, _register_device_module, _remove_batch_dim, _reshape_alias_copy, _reshape_from_tensor, _resize_output_, _rowwise_prune, _running_with_deploy, _safe_softmax, _sample_dirichlet, _saturate_weight_to_fp16, _scaled_dot_product_attention_math, _scaled_dot_product_attention_math_for_mps, _scaled_dot_product_cudnn_attention, _scaled_dot_product_efficient_attention, _scaled_dot_product_flash_attention, _scaled_dot_product_flash_attention_for_cpu, _scaled_mm, _segment_reduce, _shape_as_tensor, _sobol_engine_draw, _sobol_engine_ff_, _sobol_engine_initialize_state_, _sobol_engine_scramble_, _softmax, _softmax_backward_data, _sparse_broadcast_to, _sparse_broadcast_to_copy, _sparse_csr_prod, _sparse_csr_sum, _sparse_log_softmax_backward_data, _sparse_semi_structured_addmm, _sparse_semi_structured_apply, _sparse_semi_structured_apply_dense, _sparse_semi_structured_linear, _sparse_semi_structured_mm, _sparse_semi_structured_tile, _sparse_softmax_backward_data, _sparse_sparse_matmul, _sparse_sum, _stack, _standard_gamma, _standard_gamma_grad, _sym_acos, _sym_asin, _sym_atan, _sym_cos, _sym_cosh, _sym_log2, _sym_sin, _sym_sinh, _sym_sqrt, _sym_tan, _sym_tanh, _sync, _test_autograd_multiple_dispatch, _test_autograd_multiple_dispatch_view, _test_autograd_multiple_dispatch_view_copy, _test_check_tensor, _test_functorch_fallback, _test_parallel_materialize, _test_serialization_subcmul, _to_cpu, _to_functional_tensor, _to_sparse_semi_structured, _transform_bias_rescale_qkv, _transformer_encoder_layer_fwd, _trilinear, _triton_multi_head_attention, _triton_scaled_dot_attention, _unique, _unique2, _unpack_dual, _unsafe_index, _unsafe_index_put, _unsafe_masked_index, _unsafe_masked_index_put_accumulate, _use_cudnn_ctc_loss, _use_cudnn_rnn_flatten_weight, _validate_compressed_sparse_indices, _validate_sparse_bsc_tensor_args, _validate_sparse_bsr_tensor_args, _validate_sparse_compressed_tensor_args, _validate_sparse_coo_tensor_args, _validate_sparse_csc_tensor_args, _validate_sparse_csr_tensor_args, _values_copy, _warn_typed_storage_removal, _weight_int4pack_mm, _weight_int4pack_mm_for_cpu, _weight_int8pack_mm, _weight_norm, _weight_norm_interface, _wrapped_linear_prepack, _wrapped_quantized_linear_prepacked, abs, abs_, absolute, acos, acos_, acosh, acosh_, adaptive_avg_pool1d, adaptive_max_pool1d, add, addbmm, addcdiv, addcmul, addmm, addmv, addmv_, addr, adjoint, affine_grid_generator, alias_copy, align_tensors, all, allclose, alpha_dropout, alpha_dropout_, amax, amin, aminmax, angle, any, arange, arccos, arccos_, arccosh, arccosh_, arcsin, arcsin_, arcsinh, arcsinh_, arctan, arctan2, arctan_, arctanh, arctanh_, are_deterministic_algorithms_enabled, argmax, argmin, argsort, argwhere, as_strided, as_strided_, as_strided_copy, as_strided_scatter, as_tensor, asarray, asin, asin_, asinh, asinh_, atan, atan2, atan_, atanh, atanh_, atleast_1d, atleast_2d, atleast_3d, autocast, autocast_decrement_nesting, autocast_increment_nesting, avg_pool1d, baddbmm, bartlett_window, batch_norm, batch_norm_backward_elemt, batch_norm_backward_reduce, batch_norm_elemt, batch_norm_gather_stats, batch_norm_gather_stats_with_counts, batch_norm_stats, batch_norm_update_stats, bernoulli, bilinear, binary_cross_entropy_with_logits, bincount, binomial, bitwise_and, bitwise_left_shift, bitwise_not, bitwise_or, bitwise_right_shift, bitwise_xor, blackman_window, block_diag, bmm, broadcast_shapes, broadcast_tensors, broadcast_to, bucketize, can_cast, cartesian_prod, cat, ccol_indices_copy, cdist, ceil, ceil_, celu, celu_, chain_matmul, channel_shuffle, cholesky, cholesky_inverse, cholesky_solve, choose_qparams_optimized, chunk, clamp, clamp_, clamp_max, clamp_max_, clamp_min, clamp_min_, classproperty, clear_autocast_cache, clip, clip_, clone, col_indices_copy, column_stack, combinations, compile, compiled_with_cxx11_abi, complex, concat, concatenate, cond, conj, conj_physical, conj_physical_, constant_pad_nd, conv1d, conv2d, conv3d, conv_tbc, conv_transpose1d, conv_transpose2d, conv_transpose3d, convolution, copysign, corrcoef, cos, cos_, cosh, cosh_, cosine_embedding_loss, cosine_similarity, count_nonzero, cov, cross, crow_indices_copy, ctc_loss, cudnn_affine_grid_generator, cudnn_batch_norm, cudnn_convolution, cudnn_convolution_add_relu, cudnn_convolution_relu, cudnn_convolution_transpose, cudnn_grid_sampler, cudnn_is_acceptable, cummax, cummin, cumprod, cumsum, cumulative_trapezoid, deg2rad, deg2rad_, dequantize, det, detach, detach_, detach_copy, device, diag, diag_embed, diagflat, diagonal, diagonal_copy, diagonal_scatter, diff, digamma, dist, div, divide, dot, dropout, dropout_, dsmm, dsplit, dstack, dtype, eig, einsum, embedding, embedding_bag, embedding_renorm_, empty, empty_like, empty_permuted, empty_quantized, empty_strided, enable_grad, eq, equal, erf, erf_, erfc, erfc_, erfinv, exp, exp2, exp2_, exp_, expand_copy, expm1, expm1_, eye, fake_quantize_per_channel_affine, fake_quantize_per_tensor_affine, fbgemm_linear_fp16_weight, fbgemm_linear_fp16_weight_fp32_activation, fbgemm_linear_int8_weight, fbgemm_linear_int8_weight_fp32_activation, fbgemm_linear_quantize_weight, fbgemm_pack_gemm_matrix_fp16, fbgemm_pack_quantized_matrix, feature_alpha_dropout, feature_alpha_dropout_, feature_dropout, feature_dropout_, fill, fill_, finfo, fix, fix_, flatten, flip, fliplr, flipud, float_power, floor, floor_, floor_divide, fmax, fmin, fmod, fork, frac, frac_, frexp, frobenius_norm, from_dlpack, from_file, from_numpy, frombuffer, full, full_like, fused_moving_avg_obs_fake_quant, gather, gcd, gcd_, ge, geqrf, ger, get_autocast_cpu_dtype, get_autocast_dtype, get_autocast_gpu_dtype, get_autocast_ipu_dtype, get_autocast_xla_dtype, get_default_device, get_default_dtype, get_deterministic_debug_mode, get_device, get_device_module, get_file_path, get_float32_matmul_precision, get_num_interop_threads, get_num_threads, get_rng_state, gradient, greater, greater_equal, grid_sampler, grid_sampler_2d, grid_sampler_3d, group_norm, gru, gru_cell, gt, hamming_window, hann_window, hardshrink, heaviside, hinge_embedding_loss, histc, histogram, histogramdd, hsmm, hsplit, hspmm, hstack, hypot, i0, i0_, igamma, igammac, iinfo, imag, import_ir_module, import_ir_module_from_buffer, index_add, index_copy, index_fill, index_put, index_put_, index_reduce, index_select, indices_copy, inference_mode, init_num_threads, initial_seed, inner, instance_norm, int_repr, inverse, is_anomaly_check_nan_enabled, is_anomaly_enabled, is_autocast_cache_enabled, is_autocast_cpu_enabled, is_autocast_enabled, is_autocast_ipu_enabled, is_autocast_xla_enabled, is_complex, is_conj, is_deterministic_algorithms_warn_only_enabled, is_distributed, is_floating_point, is_grad_enabled, is_inference, is_inference_mode_enabled, is_neg, is_nonzero, is_same_size, is_signed, is_storage, is_tensor, is_vulkan_available, is_warn_always_enabled, isclose, isfinite, isin, isinf, isnan, isneginf, isposinf, isreal, istft, kaiser_window, kl_div, kron, kthvalue, layer_norm, layout, lcm, lcm_, ldexp, ldexp_, le, lerp, less, less_equal, lgamma, linspace, load, lobpcg, log, log10, log10_, log1p, log1p_, log2, log2_, log_, log_softmax, logaddexp, logaddexp2, logcumsumexp, logdet, logical_and, logical_not, logical_or, logical_xor, logit, logit_, logspace, logsumexp, lstm, lstm_cell, lstsq, lt, lu, lu_solve, lu_unpack, manual_seed, margin_ranking_loss, masked_fill, masked_scatter, masked_select, matmul, matrix_exp, matrix_power, matrix_rank, max, max_pool1d, max_pool1d_with_indices, max_pool2d, max_pool3d, maximum, mean, median, memory_format, merge_type_from_type_comment, meshgrid, min, minimum, miopen_batch_norm, miopen_convolution, miopen_convolution_add_relu, miopen_convolution_relu, miopen_convolution_transpose, miopen_depthwise_convolution, miopen_rnn, mkldnn_adaptive_avg_pool2d, mkldnn_convolution, mkldnn_linear_backward_weights, mkldnn_max_pool2d, mkldnn_max_pool3d, mkldnn_rnn_layer, mm, mode, moveaxis, movedim, msort, mul, multinomial, multiply, mv, mvlgamma, nan_to_num, nan_to_num_, nanmean, nanmedian, nanquantile, nansum, narrow, narrow_copy, native_batch_norm, native_channel_shuffle, native_dropout, native_group_norm, native_layer_norm, native_norm, ne, neg, neg_, negative, negative_, nextafter, no_grad, nonzero, nonzero_static, norm, norm_except_dim, normal, not_equal, nuclear_norm, numel, ones, ones_like, orgqr, ormqr, outer, pairwise_distance, parse_ir, parse_schema, parse_type_comment, pca_lowrank, pdist, permute, permute_copy, pinverse, pixel_shuffle, pixel_unshuffle, poisson, poisson_nll_loss, polar, polygamma, positive, pow, prelu, prepare_multiprocessing_environment, prod, promote_types, put, q_per_channel_axis, q_per_channel_scales, q_per_channel_zero_points, q_scale, q_zero_point, qr, qscheme, quantile, quantize_per_channel, quantize_per_tensor, quantize_per_tensor_dynamic, quantized_batch_norm, quantized_gru, quantized_gru_cell, quantized_lstm, quantized_lstm_cell, quantized_max_pool1d, quantized_max_pool2d, quantized_max_pool3d, quantized_rnn_relu_cell, quantized_rnn_tanh_cell, rad2deg, rad2deg_, rand, rand_like, randint, randint_like, randn, randn_like, randperm, range, ravel, read_vitals, real, reciprocal, reciprocal_, relu, relu_, remainder, renorm, repeat_interleave, reshape, resize_as_, resize_as_sparse_, resolve_conj, resolve_neg, result_type, rms_norm, rnn_relu, rnn_relu_cell, rnn_tanh, rnn_tanh_cell, roll, rot90, round, round_, row_indices_copy, row_stack, rrelu, rrelu_, rsqrt, rsqrt_, rsub, saddmm, save, scalar_tensor, scatter, scatter_add, scatter_reduce, searchsorted, seed, segment_reduce, select, select_copy, select_scatter, selu, selu_, set_anomaly_enabled, set_autocast_cache_enabled, set_autocast_cpu_dtype, set_autocast_cpu_enabled, set_autocast_dtype, set_autocast_enabled, set_autocast_gpu_dtype, set_autocast_ipu_dtype, set_autocast_ipu_enabled, set_autocast_xla_dtype, set_autocast_xla_enabled, set_default_device, set_default_dtype, set_default_tensor_type, set_deterministic_debug_mode, set_float32_matmul_precision, set_flush_denormal, set_grad_enabled, set_num_interop_threads, set_num_threads, set_printoptions, set_rng_state, set_vital, set_warn_always, sgn, sigmoid, sigmoid_, sign, signbit, sin, sin_, sinc, sinc_, sinh, sinh_, slice_copy, slice_inverse, slice_scatter, slogdet, smm, softmax, solve, sort, sparse_bsc_tensor, sparse_bsr_tensor, sparse_compressed_tensor, sparse_coo_tensor, sparse_csc_tensor, sparse_csr_tensor, split, split_copy, split_with_sizes, split_with_sizes_copy, spmm, sqrt, sqrt_, square, square_, squeeze, squeeze_copy, sspaddmm, stack, std, std_mean, stft, sub, subtract, sum, svd, svd_lowrank, swapaxes, swapdims, sym_constrain_range, sym_constrain_range_for_size, sym_float, sym_fresh_size, sym_int, sym_ite, sym_max, sym_min, sym_not, sym_sqrt, sym_sum, symeig, t, t_copy, take, take_along_dim, tan, tan_, tanh, tanh_, tensor, tensor_split, tensordot, threshold, threshold_, tile, to_dlpack, topk, trace, transpose, transpose_copy, trapezoid, trapz, triangular_solve, tril, tril_indices, triplet_margin_loss, triu, triu_indices, true_divide, trunc, trunc_, typename, unbind, unbind_copy, unflatten, unfold_copy, unify_type_list, unique, unique_consecutive, unravel_index, unsafe_chunk, unsafe_split, unsafe_split_with_sizes, unsqueeze, unsqueeze_copy, use_deterministic_algorithms, values_copy, vander, var, var_mean, vdot, view_as_complex, view_as_complex_copy, view_as_real, view_as_real_copy, view_copy, vitals_enabled, vmap, vsplit, vstack, wait, where, while_loop, xlogy, xlogy_, zero_, zeros, zeros_like
Total torch functions: 1263

Torch.nn.functional functions:
Callable, DType, List, Optional, Tensor, Tuple, Union, _adaptive_max_pool1d, _adaptive_max_pool2d, _adaptive_max_pool3d, _add_docstr, _canonical_mask, _check_key_padding_mask, _fractional_max_pool2d, _fractional_max_pool3d, _get_softmax_dim, _in_projection, _in_projection_packed, _infer_size, _is_integer, _list_with_default, _max_pool1d, _max_pool2d, _max_pool3d, _mha_shape_check, _no_grad_embedding_renorm_, _none_or_dtype, _overload, _pair, _single, _sym_int, _threshold, _triple, _unpool_output_size, _verify_batch_size, _verify_spatial_size, adaptive_avg_pool1d, adaptive_avg_pool2d, adaptive_avg_pool3d, adaptive_max_pool1d, adaptive_max_pool1d_with_indices, adaptive_max_pool2d, adaptive_max_pool2d_with_indices, adaptive_max_pool3d, adaptive_max_pool3d_with_indices, affine_grid, alpha_dropout, assert_int_or_pair, avg_pool1d, avg_pool2d, avg_pool3d, batch_norm, bilinear, binary_cross_entropy, binary_cross_entropy_with_logits, boolean_dispatch, celu, celu_, channel_shuffle, conv1d, conv2d, conv3d, conv_tbc, conv_transpose1d, conv_transpose2d, conv_transpose3d, cosine_embedding_loss, cosine_similarity, cross_entropy, ctc_loss, dropout, dropout1d, dropout2d, dropout3d, elu, elu_, embedding, embedding_bag, feature_alpha_dropout, fold, fractional_max_pool2d, fractional_max_pool2d_with_indices, fractional_max_pool3d, fractional_max_pool3d_with_indices, gaussian_nll_loss, gelu, glu, grid_sample, group_norm, gumbel_softmax, handle_torch_function, hardshrink, hardsigmoid, hardswish, hardtanh, hardtanh_, has_torch_function, has_torch_function_unary, has_torch_function_variadic, hinge_embedding_loss, huber_loss, instance_norm, interpolate, kl_div, l1_loss, layer_norm, leaky_relu, leaky_relu_, linear, local_response_norm, log_softmax, logsigmoid, lp_pool1d, lp_pool2d, lp_pool3d, margin_ranking_loss, max_pool1d, max_pool1d_with_indices, max_pool2d, max_pool2d_with_indices, max_pool3d, max_pool3d_with_indices, max_unpool1d, max_unpool2d, max_unpool3d, mish, mse_loss, multi_head_attention_forward, multi_margin_loss, multilabel_margin_loss, multilabel_soft_margin_loss, native_channel_shuffle, nll_loss, normalize, one_hot, pad, pairwise_distance, pdist, pixel_shuffle, pixel_unshuffle, poisson_nll_loss, prelu, relu, relu6, relu_, rms_norm, rrelu, rrelu_, scaled_dot_product_attention, selu, selu_, sigmoid, silu, smooth_l1_loss, soft_margin_loss, softmax, softmin, softplus, softshrink, softsign, tanh, tanhshrink, threshold, threshold_, triplet_margin_loss, triplet_margin_with_distance_loss, unfold, upsample, upsample_bilinear, upsample_nearest
Total F functions: 170

Torch.Tensor methods:
__abs__, __add__, __and__, __array__, __array_wrap__, __bool__, __class__, __complex__, __contains__, __deepcopy__, __delattr__, __delitem__, __dir__, __div__, __dlpack__, __dlpack_device__, __eq__, __float__, __floordiv__, __format__, __ge__, __getattribute__, __getitem__, __gt__, __hash__, __iadd__, __iand__, __idiv__, __ifloordiv__, __ilshift__, __imod__, __imul__, __index__, __init__, __init_subclass__, __int__, __invert__, __ior__, __ipow__, __irshift__, __isub__, __iter__, __itruediv__, __ixor__, __le__, __len__, __long__, __lshift__, __lt__, __matmul__, __mod__, __mul__, __ne__, __neg__, __new__, __nonzero__, __or__, __pos__, __pow__, __radd__, __rand__, __rdiv__, __reduce__, __reduce_ex__, __repr__, __reversed__, __rfloordiv__, __rlshift__, __rmatmul__, __rmod__, __rmul__, __ror__, __rpow__, __rrshift__, __rshift__, __rsub__, __rtruediv__, __rxor__, __setattr__, __setitem__, __setstate__, __sizeof__, __str__, __sub__, __subclasshook__, __torch_dispatch__, __torch_function__, __truediv__, __xor__, _addmm_activation, _autocast_to_full_precision, _autocast_to_reduced_precision, _clear_non_serializable_cached_data, _coalesced_, _conj, _conj_physical, _dimI, _dimV, _fix_weakref, _indices, _is_all_true, _is_any_true, _is_view, _is_zerotensor, _lazy_clone, _make_subclass, _make_wrapper_subclass, _neg_view, _nested_tensor_size, _nested_tensor_storage_offsets, _nested_tensor_strides, _nnz, _reduce_ex_internal, _rev_view_func_unsafe, _sparse_mask_projection, _to_dense, _to_sparse, _to_sparse_bsc, _to_sparse_bsr, _to_sparse_csc, _to_sparse_csr, _typed_storage, _update_names, _use_count, _values, _view_func, _view_func_unsafe, abs, abs_, absolute, absolute_, acos, acos_, acosh, acosh_, add, add_, addbmm, addbmm_, addcdiv, addcdiv_, addcmul, addcmul_, addmm, addmm_, addmv, addmv_, addr, addr_, adjoint, align_as, align_to, all, allclose, amax, amin, aminmax, angle, any, apply_, arccos, arccos_, arccosh, arccosh_, arcsin, arcsin_, arcsinh, arcsinh_, arctan, arctan2, arctan2_, arctan_, arctanh, arctanh_, argmax, argmin, argsort, argwhere, as_strided, as_strided_, as_strided_scatter, as_subclass, asin, asin_, asinh, asinh_, atan, atan2, atan2_, atan_, atanh, atanh_, backward, baddbmm, baddbmm_, bernoulli, bernoulli_, bfloat16, bincount, bitwise_and, bitwise_and_, bitwise_left_shift, bitwise_left_shift_, bitwise_not, bitwise_not_, bitwise_or, bitwise_or_, bitwise_right_shift, bitwise_right_shift_, bitwise_xor, bitwise_xor_, bmm, bool, broadcast_to, byte, cauchy_, ccol_indices, cdouble, ceil, ceil_, cfloat, chalf, char, cholesky, cholesky_inverse, cholesky_solve, chunk, clamp, clamp_, clamp_max, clamp_max_, clamp_min, clamp_min_, clip, clip_, clone, coalesce, col_indices, conj, conj_physical, conj_physical_, contiguous, copy_, copysign, copysign_, corrcoef, cos, cos_, cosh, cosh_, count_nonzero, cov, cpu, cross, crow_indices, cuda, cummax, cummin, cumprod, cumprod_, cumsum, cumsum_, data_ptr, deg2rad, deg2rad_, dense_dim, dequantize, det, detach, detach_, diag, diag_embed, diagflat, diagonal, diagonal_scatter, diff, digamma, digamma_, dim, dim_order, dist, div, div_, divide, divide_, dot, double, dsplit, eig, element_size, eq, eq_, equal, erf, erf_, erfc, erfc_, erfinv, erfinv_, exp, exp2, exp2_, exp_, expand, expand_as, expm1, expm1_, exponential_, fill_, fill_diagonal_, fix, fix_, flatten, flip, fliplr, flipud, float, float_power, float_power_, floor, floor_, floor_divide, floor_divide_, fmax, fmin, fmod, fmod_, frac, frac_, frexp, gather, gcd, gcd_, ge, ge_, geometric_, geqrf, ger, get_device, greater, greater_, greater_equal, greater_equal_, gt, gt_, half, hardshrink, has_names, heaviside, heaviside_, histc, histogram, hsplit, hypot, hypot_, i0, i0_, igamma, igamma_, igammac, igammac_, index_add, index_add_, index_copy, index_copy_, index_fill, index_fill_, index_put, index_put_, index_reduce, index_reduce_, index_select, indices, inner, int, int_repr, inverse, ipu, is_coalesced, is_complex, is_conj, is_contiguous, is_distributed, is_floating_point, is_inference, is_neg, is_nonzero, is_pinned, is_same_size, is_set_to, is_shared, is_signed, isclose, isfinite, isinf, isnan, isneginf, isposinf, isreal, istft, item, kron, kthvalue, lcm, lcm_, ldexp, ldexp_, le, le_, lerp, lerp_, less, less_, less_equal, less_equal_, lgamma, lgamma_, log, log10, log10_, log1p, log1p_, log2, log2_, log_, log_normal_, log_softmax, logaddexp, logaddexp2, logcumsumexp, logdet, logical_and, logical_and_, logical_not, logical_not_, logical_or, logical_or_, logical_xor, logical_xor_, logit, logit_, logsumexp, long, lstsq, lt, lt_, lu, lu_solve, map2_, map_, masked_fill, masked_fill_, masked_scatter, masked_scatter_, masked_select, matmul, matrix_exp, matrix_power, max, maximum, mean, median, min, minimum, mm, mode, module_load, moveaxis, movedim, msort, mtia, mul, mul_, multinomial, multiply, multiply_, mv, mvlgamma, mvlgamma_, nan_to_num, nan_to_num_, nanmean, nanmedian, nanquantile, nansum, narrow, narrow_copy, ndimension, ne, ne_, neg, neg_, negative, negative_, nelement, new, new_empty, new_empty_strided, new_full, new_ones, new_tensor, new_zeros, nextafter, nextafter_, nonzero, nonzero_static, norm, normal_, not_equal, not_equal_, numel, numpy, orgqr, ormqr, outer, permute, pin_memory, pinverse, polygamma, polygamma_, positive, pow, pow_, prelu, prod, put, put_, q_per_channel_axis, q_per_channel_scales, q_per_channel_zero_points, q_scale, q_zero_point, qr, qscheme, quantile, rad2deg, rad2deg_, random_, ravel, reciprocal, reciprocal_, record_stream, refine_names, register_hook, register_post_accumulate_grad_hook, reinforce, relu, relu_, remainder, remainder_, rename, rename_, renorm, renorm_, repeat, repeat_interleave, requires_grad_, reshape, reshape_as, resize, resize_, resize_as, resize_as_, resize_as_sparse_, resolve_conj, resolve_neg, retain_grad, roll, rot90, round, round_, row_indices, rsqrt, rsqrt_, scatter, scatter_, scatter_add, scatter_add_, scatter_reduce, scatter_reduce_, select, select_scatter, set_, sgn, sgn_, share_memory_, short, sigmoid, sigmoid_, sign, sign_, signbit, sin, sin_, sinc, sinc_, sinh, sinh_, size, slice_inverse, slice_scatter, slogdet, smm, softmax, solve, sort, sparse_dim, sparse_mask, sparse_resize_, sparse_resize_and_clear_, split, split_with_sizes, sqrt, sqrt_, square, square_, squeeze, squeeze_, sspaddmm, std, stft, storage, storage_offset, storage_type, stride, sub, sub_, subtract, subtract_, sum, sum_to_size, svd, swapaxes, swapaxes_, swapdims, swapdims_, symeig, t, t_, take, take_along_dim, tan, tan_, tanh, tanh_, tensor_split, tile, to, to_dense, to_mkldnn, to_padded_tensor, to_sparse, to_sparse_bsc, to_sparse_bsr, to_sparse_coo, to_sparse_csc, to_sparse_csr, tolist, topk, trace, transpose, transpose_, triangular_solve, tril, tril_, triu, triu_, true_divide, true_divide_, trunc, trunc_, type, type_as, unbind, unflatten, unfold, uniform_, unique, unique_consecutive, unsafe_chunk, unsafe_split, unsafe_split_with_sizes, unsqueeze, unsqueeze_, untyped_storage, values, var, vdot, view, view_as, vsplit, where, xlogy, xlogy_, xpu, zero_
Total tensor methods: 696
